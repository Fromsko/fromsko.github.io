# AI-agent-notebook

Below is an example of a code cell.
Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.

Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.

To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).
For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html).

```python
from typing import Dict, List, Literal, Optional, Union

OutputType = Literal["pure_code", "text_with_code", "explanation"]
LanguageType = Literal["json", "python", "bash", "sql", "custom"]

def build_prompt_json(
    input_data: str,
    output_type: OutputType = "pure_code",
    language: LanguageType = "json",
    additional_constraints: Optional[List[str]] = None
) -> Dict[str, Union[str, Dict, List]]:
    """
    æ„å»ºæ ‡å‡†åŒ–ç»“æ„çš„æç¤ºè¯ JSON å¯¹è±¡ã€‚

    Args:
        input_data (str): ç”¨æˆ·è¾“å…¥çš„ç®€å•æƒ³æ³•æˆ–éœ€æ±‚ã€‚
        output_type (OutputType): æŒ‡å®šè¾“å‡ºç±»å‹ã€‚
        language (LanguageType): æŒ‡å®šç”Ÿæˆä»£ç çš„è¯­è¨€ã€‚
        additional_constraints (Optional[List[str]]): å¯é€‰çš„é™„åŠ çº¦æŸæ¡ä»¶ã€‚

    Returns:
        Dict[str, Union[str, Dict, List]]: æ ‡å‡†åŒ–æç¤ºè¯ JSONã€‚
    """
    base_constraints = [
        "ç”Ÿæˆçš„æç¤ºè¯å¿…é¡»æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡å­—ç¬¦ä¸²ã€‚",
        "ç”Ÿæˆçš„æç¤ºè¯åº”åŒ…å«role, task_description, context, constraints, å’Œ output_specification å­—æ®µã€‚"
    ]

    if additional_constraints:
        base_constraints.extend(additional_constraints)

    prompt_json = {
        "role": "ä½ æ˜¯ä¸€ä½æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰ä¸“å®¶ã€‚",
        "task_description": (
            "è¯·å°†'input_data'ä¸­çš„ç®€å•æƒ³æ³•ï¼Œæ‰©å±•æˆä¸€ä¸ªå®Œæ•´ã€é«˜æ•ˆçš„ç»“æ„åŒ–JSONæç¤ºè¯ã€‚"
            "ç”Ÿæˆçš„æç¤ºè¯æœ¬èº«åº”è¯¥ç¬¦åˆæœ¬æ–‡æ¡£å®šä¹‰çš„é€šç”¨ç»“æ„ã€‚"
        ),
        "context": {
            "input_data": input_data
        },
        "constraints": base_constraints,
        "output_specification": {
            "type": output_type,
            "details": {
                "schema": {
                    "language": language,
                    "code": "string"
                }
            }
        }
    }

    return prompt_json
```

# Prompt ç”ŸæˆåŠ©æ‰‹

> è‡ªåŠ¨ Prompt ç”Ÿæˆï¼Œå¸®åŠ©æŒ‡å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„ä»»åŠ¡

```python
if __name__ == "__main__":
    result = build_prompt_json(
        input_data="æ¨¡æ‹Ÿä¸€ä¸ª Linux ç»ˆç«¯ï¼Œå“åº”ç”¨æˆ·è¾“å…¥çš„æŒ‡ä»¤ã€‚",
        output_type="pure_code",
        language="json",
        additional_constraints=["ä¸è¦åŒ…å«ä»»ä½•ä¸èº«ä»½ç›¸å…³çš„è¯´æ˜ã€‚"]
    )

    import json
    print(json.dumps(result, ensure_ascii=False, indent=2))
```

```
{
  "role": "ä½ æ˜¯ä¸€ä½æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰ä¸“å®¶ã€‚",
  "task_description": "è¯·å°†'input_data'ä¸­çš„ç®€å•æƒ³æ³•ï¼Œæ‰©å±•æˆä¸€ä¸ªå®Œæ•´ã€é«˜æ•ˆçš„ç»“æ„åŒ–JSONæç¤ºè¯ã€‚ç”Ÿæˆçš„æç¤ºè¯æœ¬èº«åº”è¯¥ç¬¦åˆæœ¬æ–‡æ¡£å®šä¹‰çš„é€šç”¨ç»“æ„ã€‚",
  "context": {
    "input_data": "æ¨¡æ‹Ÿä¸€ä¸ª Linux ç»ˆç«¯ï¼Œå“åº”ç”¨æˆ·è¾“å…¥çš„æŒ‡ä»¤ã€‚"
  },
  "constraints": [
    "ç”Ÿæˆçš„æç¤ºè¯å¿…é¡»æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡å­—ç¬¦ä¸²ã€‚",
    "ç”Ÿæˆçš„æç¤ºè¯åº”åŒ…å«role, task_description, context, constraints, å’Œ output_specification å­—æ®µã€‚",
    "ä¸è¦åŒ…å«ä»»ä½•ä¸èº«ä»½ç›¸å…³çš„è¯´æ˜ã€‚"
  ],
  "output_specification": {
    "type": "pure_code",
    "details": {
      "schema": {
        "language": "json",
        "code": "string"
      }
    }
  }
}
```

```python
import nest_asyncio
nest_asyncio.apply()
```

```python
from dataclasses import dataclass
import asyncio
import httpx
from typing import Dict, Any

from pydantic_ai import Agent, RunContext, ModelRetry
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider

# é…ç½® Qwen OpenAI å…¼å®¹ API
QWEN_API = "sk-xxx"

qwen_provider = OpenAIProvider(
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=QWEN_API,
)

qwen3_model = OpenAIModel(
    model_name="qwen-plus-latest",
    provider=qwen_provider,
)

# ä¾èµ–é¡¹å®šä¹‰
@dataclass
class MyDeps:
    api_key: str
    http_client: httpx.AsyncClient

# åˆ›å»º Agent
agent = Agent(
    model=qwen3_model,
    deps_type=MyDeps,
    result_type=Dict[str, Any],  # æˆ‘ä»¬æœŸæœ›è¿”å›ç»“æ„åŒ– JSON
    retries=2
)

# ç³»ç»Ÿ Prompt ç”Ÿæˆ
@agent.system_prompt
async def get_system_prompt(ctx: RunContext[MyDeps]) -> str:
    return (
        "ä½ æ˜¯ä¸€ä½æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰ä¸“å®¶ã€‚"
        "è¯·æ ¹æ® input_data æ„å»ºä¸€ä¸ªæ ‡å‡†åŒ– JSON Promptï¼Œè¦æ±‚åŒ…å«ä»¥ä¸‹å­—æ®µï¼š"
        "role, task_description, context, constraints, output_specificationã€‚"
        "è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON å­—ç¬¦ä¸²ï¼Œä¸åŒ…å«ä»»ä½•é¢å¤–æ–‡å­—æˆ–è§£é‡Šã€‚"
    )

# å·¥å…·ï¼šè·å–å¤–éƒ¨æç¤ºç‰‡æ®µ (å¯é€‰)
@agent.tool
async def fetch_hint(ctx: RunContext[MyDeps], url: str) -> str:
    response = await ctx.deps.http_client.get(url)
    response.raise_for_status()
    return response.text

# ç»“æœæ ¡éªŒå™¨
@agent.output_validator
async def validate_json_result(ctx: RunContext[MyDeps], final_response: Dict[str, Any]) -> Dict[str, Any]:
    # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å­˜åœ¨
    required_fields = {"role", "task_description", "context", "constraints", "output_specification"}
    if not required_fields.issubset(final_response.keys()):
        raise ModelRetry(f"Missing fields in response: {required_fields - final_response.keys()}")
    return final_response

# ä¸»è¿è¡Œé€»è¾‘
async def main():
    async with httpx.AsyncClient() as client:
        deps = MyDeps(api_key=QWEN_API, http_client=client)

        input_idea = "æ¨¡æ‹Ÿä¸€ä¸ª Linux ç»ˆç«¯ï¼Œå“åº”ç”¨æˆ·è¾“å…¥çš„æŒ‡ä»¤ã€‚"

        user_input = {
            "input_data": input_idea,
            "constraints": [
                "ç”Ÿæˆçš„æç¤ºè¯å¿…é¡»æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡å­—ç¬¦ä¸²ã€‚",
                "ç”Ÿæˆçš„æç¤ºè¯åº”åŒ…å«role, task_description, context, constraints, å’Œ output_specification å­—æ®µã€‚",
                "ä¸è¦åŒ…å«ä¸èº«ä»½ç›¸å…³çš„è¯´æ˜ã€‚"
            ]
        }

        result = await agent.run(user_input, deps=deps)

        # è¾“å‡ºç”Ÿæˆçš„æ ‡å‡†åŒ– JSON Prompt
        import json
        print(json.dumps(result.output, ensure_ascii=False, indent=2))
await main()

```

```
{
  "role": "æç¤ºå·¥ç¨‹ä¸“å®¶",
  "task_description": "æ ¹æ®è¾“å…¥æ•°æ®æ„å»ºä¸€ä¸ªæ ‡å‡†åŒ–çš„ JSON Promptã€‚",
  "context": "ç”¨æˆ·æä¾›äº† input_data å’Œ constraints å­—æ®µï¼Œéœ€è¦å°†å…¶æ•´åˆåˆ°æ ‡å‡†åŒ–çš„ JSON Prompt ä¸­ã€‚",
  "constraints": "è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ JSON å­—ç¬¦ä¸²ï¼ŒåŒ…å« roleã€task_descriptionã€contextã€constraints å’Œ output_specification å­—æ®µï¼Œä¸”ä¸åŒ…å«ä»»ä½•é¢å¤–æ–‡å­—æˆ–è§£é‡Šã€‚",
  "output_specification": "JSON å¯¹è±¡ï¼Œå­—æ®µåŒ…æ‹¬ role (å­—ç¬¦ä¸²)ã€task_description (å­—ç¬¦ä¸²)ã€context (å­—ç¬¦ä¸²)ã€constraints (å­—ç¬¦ä¸²)ã€output_specification (å­—ç¬¦ä¸²)ã€‚"
}
```

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
import asyncio
import json
import os
from typing import List, Dict, Any
import httpx

from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider


# === é…ç½®æ¨¡å‹ ===
qwen_provider = OpenAIProvider(
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=QWEN_API,
)
qwen_model = OpenAIModel(model_name="qwen-plus-latest", provider=qwen_provider)


@dataclass
class Deps:
    api_key: str
    http_client: httpx.AsyncClient


# === åŸºç¡€ç»„ä»¶ ===
class TaskPlanner(ABC):
    @abstractmethod
    async def plan_tasks(self, input_data: str) -> List[str]:
        ...


class SQLTaskPlanner(TaskPlanner):
    """å°†ç”¨æˆ·éœ€æ±‚æ‹†è§£æˆå­ä»»åŠ¡"""
    async def plan_tasks(self, input_data: str) -> List[str]:
        # ç®€åŒ–ï¼Œå®é™…å¯ä»¥ç”¨æ¨¡å‹å»åšè§„åˆ’
        return [
            "è¯»å–é¢˜ç›®å¹¶ç†è§£éœ€æ±‚",
            "åˆ†æSQLæ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰",
            "ç¼–å†™SQLè§£é‡Šå™¨ Agent ä»£ç ",
            "ç¼–å†™SQLä½œä¸šä»£ç ",
            "é€æ¡æ‰§è¡ŒSQLè¿›è¡Œæµ‹è¯•"
        ]


class AgentWorker:
    """ç»„åˆå¤šä¸ªå­ Agent æ‰§è¡Œå­ä»»åŠ¡"""
    def __init__(self, model, deps: Deps):
        self.model = model
        self.deps = deps

    async def run_task(self, instruction: str) -> str:
        agent = Agent(
            model=self.model,
            deps_type=Deps,
        )

        @agent.system_prompt
        async def system_prompt(ctx: RunContext[Deps]) -> str:
            return (
                "ä½ æ˜¯ä¸€ä¸ªSQLä½œä¸šåŠ©æ‰‹ï¼Œè¯·å®Œæˆç”¨æˆ·è¦æ±‚çš„ä»»åŠ¡ã€‚"
                "ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯çº¯ä»£ç æˆ–çº¯è§£é‡Šï¼Œä¸å¾—åŒ…å«åºŸè¯ã€‚"
            )

        result = await agent.run(instruction, deps=self.deps)
        return result.output


class OutputManager(ABC):
    @abstractmethod
    def save(self, filename: str, content: str):
        ...


class FileOutputManager(OutputManager):
    """ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°ç£ç›˜"""
    def save(self, filename: str, content: str):
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        with open(filename, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"[âœ… å·²ä¿å­˜] {filename}")


# === ä¸»æµç¨‹æ¨¡æ¿ ===
class WorkflowEngine:
    def __init__(self, planner: TaskPlanner, worker: AgentWorker, output_mgr: OutputManager):
        self.planner = planner
        self.worker = worker
        self.output_mgr = output_mgr

    async def execute(self, user_input: str, output_file: str):
        # 1ï¸âƒ£ æ‹†è§£ä»»åŠ¡
        print("[ğŸš€] æ­£åœ¨æ‹†è§£ä»»åŠ¡...")
        tasks = await self.planner.plan_tasks(user_input)
        print(f"[ğŸ“‹] æ‹†è§£å‡ºçš„ä»»åŠ¡: {tasks}")

        # 2ï¸âƒ£ æ‰§è¡Œå­ä»»åŠ¡
        all_results = {}
        for i, task in enumerate(tasks, 1):
            print(f"[âš™ï¸] æ­£åœ¨æ‰§è¡Œå­ä»»åŠ¡ {i}: {task}")
            result = await self.worker.run_task(f"ä»»åŠ¡ï¼š{task}\nç”¨æˆ·éœ€æ±‚ï¼š{user_input}")
            all_results[f"Task {i}: {task}"] = result
            print(f"[âœ…] å­ä»»åŠ¡ {i} å®Œæˆ")

        # 3ï¸âƒ£ ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£
        final_doc = json.dumps(all_results, ensure_ascii=False, indent=2)
        self.output_mgr.save(output_file, final_doc)
        print("[ğŸ‰] å·¥ä½œæµå®Œæˆï¼")


# === ä¸»è¿è¡Œ ===
async def main():
    async with httpx.AsyncClient() as client:
        deps = Deps(api_key=QWEN_API, http_client=client)

        planner = SQLTaskPlanner()
        worker = AgentWorker(model=qwen_model, deps=deps)
        output_mgr = FileOutputManager()

        engine = WorkflowEngine(planner, worker, output_mgr)

        user_input = "å®Œæˆä¸€ä»½SQLä½œä¸šï¼ŒåŒ…å«3é“é¢˜ç›®ï¼Œæ¯é¢˜ç»™å‡ºé¢˜è§£å’ŒSQLä»£ç ï¼Œå¹¶æµ‹è¯•å…¶æ­£ç¡®æ€§ã€‚"
        output_file = "output/sql_homework.json"

        await engine.execute(user_input, output_file)


# è°ƒç”¨æ—¶æ ¹æ®ç¯å¢ƒé€‰æ‹© run æ–¹å¼
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except RuntimeError:
        # ç”¨äº notebook æˆ–å·²æœ‰äº‹ä»¶å¾ªç¯ç¯å¢ƒ
        import nest_asyncio
        nest_asyncio.apply()
        asyncio.get_event_loop().run_until_complete(main())

```

```
[ğŸš€] æ­£åœ¨æ‹†è§£ä»»åŠ¡...
[ğŸ“‹] æ‹†è§£å‡ºçš„ä»»åŠ¡: ['è¯»å–é¢˜ç›®å¹¶ç†è§£éœ€æ±‚', 'åˆ†æSQLæ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰', 'ç¼–å†™SQLè§£é‡Šå™¨ Agent ä»£ç ', 'ç¼–å†™SQLä½œä¸šä»£ç ', 'é€æ¡æ‰§è¡ŒSQLè¿›è¡Œæµ‹è¯•']
[âš™ï¸] æ­£åœ¨æ‰§è¡Œå­ä»»åŠ¡ 1: è¯»å–é¢˜ç›®å¹¶ç†è§£éœ€æ±‚
[âœ…] å­ä»»åŠ¡ 1 å®Œæˆ
[âš™ï¸] æ­£åœ¨æ‰§è¡Œå­ä»»åŠ¡ 2: åˆ†æSQLæ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
[âœ…] å­ä»»åŠ¡ 2 å®Œæˆ
[âš™ï¸] æ­£åœ¨æ‰§è¡Œå­ä»»åŠ¡ 3: ç¼–å†™SQLè§£é‡Šå™¨ Agent ä»£ç 
[âœ…] å­ä»»åŠ¡ 3 å®Œæˆ
[âš™ï¸] æ­£åœ¨æ‰§è¡Œå­ä»»åŠ¡ 4: ç¼–å†™SQLä½œä¸šä»£ç 
[âœ…] å­ä»»åŠ¡ 4 å®Œæˆ
[âš™ï¸] æ­£åœ¨æ‰§è¡Œå­ä»»åŠ¡ 5: é€æ¡æ‰§è¡ŒSQLè¿›è¡Œæµ‹è¯•
[âœ…] å­ä»»åŠ¡ 5 å®Œæˆ
[âœ… å·²ä¿å­˜] output/sql_homework.json
[ğŸ‰] å·¥ä½œæµå®Œæˆï¼
```

```python
import os
import json
import asyncio
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import List, Dict
import httpx

from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider


# === æ¨¡å‹é…ç½® ===
QWEN_API = "sk-xxx"
qwen_provider = OpenAIProvider(
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=QWEN_API,
)
qwen_model = OpenAIModel(model_name="qwen-plus-latest", provider=qwen_provider)


@dataclass
class Deps:
    api_key: str
    http_client: httpx.AsyncClient
    data_files: Dict[str, str]  # æ–‡ä»¶å -> æ–‡ä»¶å†…å®¹


# === æ–‡ä»¶å·¥å…· ===
class FileLoader:
    @staticmethod
    def load_data_files(directory: str = "data") -> Dict[str, str]:
        files = {}
        for fame in os.listdir(directory):
            fpath = os.path.join(directory, fame)
            if os.path.isfile(fpath):
                with open(fpath, "r", encoding="utf-8") as f:
                    files[fame] = f.read()
        return files

    @staticmethod
    def save_markdown_step(step_name: str, content: str, directory: str = "output/steps"):
        os.makedirs(directory, exist_ok=True)
        file_path = os.path.join(directory, f"{step_name}.md")
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"# {step_name}\n\n")
            f.write(content)
        print(f"[ğŸ“„] æ­¥éª¤å·²ä¿å­˜: {file_path}")

    @staticmethod
    def save_final_code(content: str, filename: str = "output/final_code.sql"):
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        with open(filename, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"[âœ…] æœ€ç»ˆä»£ç å·²ä¿å­˜: {filename}")


# === ä»»åŠ¡è§„åˆ’å™¨ ===
class TaskPlanner(ABC):
    @abstractmethod
    async def plan_tasks(self, input_data: str) -> List[str]:
        ...


class SQLTaskPlanner(TaskPlanner):
    async def plan_tasks(self, input_data: str) -> List[str]:
        return [
            "åˆ†æ data æ–‡ä»¶å¤¹ä¸­å¯ç”¨èµ„æºï¼Œå¹¶å†³å®šéœ€è¦å“ªäº›æ–‡ä»¶ç”¨äºä½œä¸š",
            "åŸºäºèµ„æºåˆ¶å®šSQLä½œä¸šè®¡åˆ’",
            "ç¼–å†™SQLä½œä¸šä»£ç ",
            "é€æ¡æ‰§è¡ŒSQLå¹¶éªŒè¯ç»“æœ",
            "ç”Ÿæˆå®Œæ•´SQLä½œä¸šæ–‡ä»¶åŠé¢˜è§£"
        ]


# === å·¥ä½œæ‰§è¡Œå™¨ ===
class AgentWorker:
    def __init__(self, model, deps: Deps):
        self.model = model
        self.deps = deps
        self.agent = Agent(
            model=self.model,
            deps_type=Deps,
        )

        self._register_tools()

    def _register_tools(self):
        @self.agent.tool
        async def list_data_files(ctx: RunContext[Deps]) -> str:
            return json.dumps(list(ctx.deps.data_files.keys()), ensure_ascii=False)

        @self.agent.tool
        async def read_data_file(ctx: RunContext[Deps], filename: str) -> str:
            return ctx.deps.data_files.get(filename, f"æ–‡ä»¶ {filename} ä¸å­˜åœ¨")

    async def run_task(self, instruction: str) -> str:
        @self.agent.system_prompt
        async def system_prompt(ctx: RunContext[Deps]) -> str:
            return (
                "ä½ æ˜¯SQLä½œä¸šAIåŠ©æ‰‹ã€‚è¯·å……åˆ†åˆ©ç”¨æä¾›çš„dataç›®å½•æ–‡ä»¶ï¼Œé€šè¿‡å·¥å…·å‡½æ•° list_data_files å’Œ read_data_file æ¥è¾…åŠ©ä½ å®Œæˆä»»åŠ¡ã€‚"
                "æ¯ä¸€æ­¥è¾“å‡ºå¿…é¡»æ˜¯ä¸¥è°¨çš„Markdownæ ¼å¼è¯´æ˜æˆ–SQLä»£ç ï¼Œæ— åºŸè¯ã€‚"
            )

        result = await self.agent.run(instruction, deps=self.deps)
        return result.output


# === å·¥ä½œæµå¼•æ“ ===
class WorkflowEngine:
    def __init__(self, planner: TaskPlanner, worker: AgentWorker):
        self.planner = planner
        self.worker = worker

    async def execute(self, user_input: str):
        print("[ğŸš€] å¼€å§‹ä»»åŠ¡è§„åˆ’...")
        tasks = await self.planner.plan_tasks(user_input)
        print(f"[ğŸ“‹] ä»»åŠ¡åˆ†è§£: {tasks}")

        combined_sql_code = ""

        for idx, task in enumerate(tasks, 1):
            step_name = f"Step{idx}_{task[:30].replace(' ', '_')}"
            print(f"[âš™ï¸] æ­£åœ¨æ‰§è¡Œ: {task}")
            output = await self.worker.run_task(f"{task}\nç”¨æˆ·éœ€æ±‚: {user_input}")
            FileLoader.save_markdown_step(step_name, output)

            # ç®€åŒ–é€»è¾‘ï¼šå¦‚æœè¾“å‡ºé‡Œæœ‰SQLä»£ç ï¼Œå°±æ‹¼æ¥ï¼ˆå¯æ”¹è¿›ä¸ºç²¾å‡†æå–ï¼‰
            if "SELECT" in output.upper() or "INSERT" in output.upper() or "CREATE" in output.upper():
                combined_sql_code += output + "\n\n"

        # æœ€ç»ˆä¿å­˜å®Œæ•´SQLæ–‡ä»¶
        FileLoader.save_final_code(combined_sql_code)


# === ä¸»å‡½æ•° ===
async def main():
    async with httpx.AsyncClient() as client:
        data_files = FileLoader.load_data_files("data")
        deps = Deps(api_key=QWEN_API, http_client=client, data_files=data_files)

        planner = SQLTaskPlanner()
        worker = AgentWorker(model=qwen_model, deps=deps)
        engine = WorkflowEngine(planner, worker)

        user_input = "å®Œæˆä¸€ä»½SQLä½œä¸šï¼ŒåŒ…å«é¢˜è§£å’Œé€æ­¥éªŒè¯ã€‚"
        await engine.execute(user_input)


# === å¯åŠ¨ ===
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except RuntimeError:
        # å…¼å®¹ Jupyter
        import nest_asyncio
        nest_asyncio.apply()
        asyncio.get_event_loop().run_until_complete(main())

```

```
[ğŸš€] å¼€å§‹ä»»åŠ¡è§„åˆ’...
[ğŸ“‹] ä»»åŠ¡åˆ†è§£: ['åˆ†æ data æ–‡ä»¶å¤¹ä¸­å¯ç”¨èµ„æºï¼Œå¹¶å†³å®šéœ€è¦å“ªäº›æ–‡ä»¶ç”¨äºä½œä¸š', 'åŸºäºèµ„æºåˆ¶å®šSQLä½œä¸šè®¡åˆ’', 'ç¼–å†™SQLä½œä¸šä»£ç ', 'é€æ¡æ‰§è¡ŒSQLå¹¶éªŒè¯ç»“æœ', 'ç”Ÿæˆå®Œæ•´SQLä½œä¸šæ–‡ä»¶åŠé¢˜è§£']
[âš™ï¸] æ­£åœ¨æ‰§è¡Œ: åˆ†æ data æ–‡ä»¶å¤¹ä¸­å¯ç”¨èµ„æºï¼Œå¹¶å†³å®šéœ€è¦å“ªäº›æ–‡ä»¶ç”¨äºä½œä¸š
[ğŸ“„] æ­¥éª¤å·²ä¿å­˜: output/steps\Step1_åˆ†æ_data_æ–‡ä»¶å¤¹ä¸­å¯ç”¨èµ„æºï¼Œå¹¶å†³å®šéœ€è¦å“ªäº›æ–‡ä»¶ç”¨äºä½œä¸š.md
[âš™ï¸] æ­£åœ¨æ‰§è¡Œ: åŸºäºèµ„æºåˆ¶å®šSQLä½œä¸šè®¡åˆ’
[ğŸ“„] æ­¥éª¤å·²ä¿å­˜: output/steps\Step2_åŸºäºèµ„æºåˆ¶å®šSQLä½œä¸šè®¡åˆ’.md
[âš™ï¸] æ­£åœ¨æ‰§è¡Œ: ç¼–å†™SQLä½œä¸šä»£ç 
[ğŸ“„] æ­¥éª¤å·²ä¿å­˜: output/steps\Step3_ç¼–å†™SQLä½œä¸šä»£ç .md
[âš™ï¸] æ­£åœ¨æ‰§è¡Œ: é€æ¡æ‰§è¡ŒSQLå¹¶éªŒè¯ç»“æœ
[ğŸ“„] æ­¥éª¤å·²ä¿å­˜: output/steps\Step4_é€æ¡æ‰§è¡ŒSQLå¹¶éªŒè¯ç»“æœ.md
[âš™ï¸] æ­£åœ¨æ‰§è¡Œ: ç”Ÿæˆå®Œæ•´SQLä½œä¸šæ–‡ä»¶åŠé¢˜è§£
[ğŸ“„] æ­¥éª¤å·²ä¿å­˜: output/steps\Step5_ç”Ÿæˆå®Œæ•´SQLä½œä¸šæ–‡ä»¶åŠé¢˜è§£.md
[âœ…] æœ€ç»ˆä»£ç å·²ä¿å­˜: output/final_code.sql


C:\Users\16143\AppData\Local\Temp\ipykernel_46248\1519857319.py:159: RuntimeWarning: coroutine 'main' was never awaited
  asyncio.get_event_loop().run_until_complete(main())
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
```

```python
import os
import json
import asyncio
from abc import ABC, abstractmethod
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider


# é…ç½® Qwen API
QWEN_API = "sk-xxx"


# å·¥å‚ï¼šåŠ¨æ€ç”Ÿæˆå¸¦è‡ªå®šä¹‰ prompt çš„ Agent
def create_agent(prompt: str):
    provider = OpenAIProvider(
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        api_key=QWEN_API,
    )
    model = OpenAIModel(model_name="qwen-plus-latest", provider=provider)
    agent = Agent(model=model)

    @agent.system_prompt
    def dynamic_prompt(_):
        return prompt

    return agent


# æ–‡ä»¶ç®¡ç†å·¥å…·
class FileManager:
    @staticmethod
    def load_data_files(data_dir="data"):
        files = {}
        for f in os.listdir(data_dir):
            path = os.path.join(data_dir, f)
            if os.path.isfile(path):
                with open(path, "r", encoding="utf-8") as file:
                    files[f] = file.read()
        return files

    @staticmethod
    def save_markdown_step(name, content, out_dir="output/steps"):
        os.makedirs(out_dir, exist_ok=True)
        file_path = os.path.join(out_dir, f"{name}.md")
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"# {name}\n\n{content}")
        print(f"[ä¿å­˜] {name} å·²å†™å…¥: {file_path}")

    @staticmethod
    def save_final_code(content, out_file="output/final_code.sql"):
        os.makedirs(os.path.dirname(out_file), exist_ok=True)
        with open(out_file, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"[ä¿å­˜] æœ€ç»ˆä»£ç å·²å†™å…¥: {out_file}")


# ä¸Šä¸‹æ–‡
class Context:
    def __init__(self, data_files):
        self.data_files = data_files
        self._results = {}

    def add_result(self, key, value):
        self._results[key] = value

    def get_result(self, key):
        return self._results.get(key, "")


# ç­–ç•¥åŸºç±»
class TaskStrategy(ABC):
    @abstractmethod
    async def run(self, context: Context):
        ...


# å„ç§ç­–ç•¥
class AnalyzeResourceStrategy(TaskStrategy):
    async def run(self, context: Context):
        agent = create_agent(
            "ä½ æ˜¯ä¸“ä¸šSQLä½œä¸šåŠ©æ‰‹ï¼Œè¯·åˆ†ædataç›®å½•æ–‡ä»¶å¹¶é€‰æ‹©å¯¹ä»»åŠ¡æœ€æœ‰å¸®åŠ©çš„æ–‡ä»¶ï¼Œè¿”å›åŸå› å’Œæ–‡ä»¶åï¼ˆJSONç»“æ„ï¼‰ã€‚"
        )
        files = list(context.data_files.keys())
        instruction = f"å¯ç”¨æ–‡ä»¶ï¼š{files}"
        result = await agent.run(instruction)
        FileManager.save_markdown_step("01_åˆ†æèµ„æº", result.output)
        context.add_result("resource_analysis", result.output)


class PlanSQLTaskStrategy(TaskStrategy):
    async def run(self, context: Context):
        agent = create_agent(
            "ä½ æ˜¯ä¸“ä¸šSQLä½œä¸šåŠ©æ‰‹ï¼Œæ ¹æ®æä¾›çš„æ–‡ä»¶åˆ†æç»“æœï¼Œåˆ¶å®šå®Œæ•´SQLä½œä¸šè®¡åˆ’ã€‚åŒ…æ‹¬æ¯é¢˜çš„è§£é¢˜æ€è·¯ã€éªŒè¯æ­¥éª¤ã€‚è¾“å‡ºJSONç»“æ„ã€‚"
        )
        result = await agent.run(context.get_result("resource_analysis"))
        FileManager.save_markdown_step("02_ä»»åŠ¡è§„åˆ’", result.output)
        context.add_result("task_plan", result.output)


class GenerateSQLCodeStrategy(TaskStrategy):
    async def run(self, context: Context):
        agent = create_agent(
            "æ ¹æ®SQLä½œä¸šè®¡åˆ’ï¼Œç”Ÿæˆå®Œæ•´SQLä»£ç å’Œæ³¨é‡Šï¼Œæ¯é¢˜çš„ä»£ç æŒ‰é¡ºåºè¾“å‡ºã€‚"
        )
        result = await agent.run(context.get_result("task_plan"))
        FileManager.save_markdown_step("03_SQLä»£ç ç”Ÿæˆ", result.output)
        context.add_result("sql_code", result.output)
        FileManager.save_final_code(result.output)


# å·¥ä½œæµå¼•æ“
class WorkflowEngine:
    def __init__(self, strategies):
        self.strategies = strategies

    async def run(self, context: Context):
        for strategy in self.strategies:
            await strategy.run(context)


# ä¸»å‡½æ•°
async def main():
    data_files = FileManager.load_data_files()
    context = Context(data_files)

    strategies = [
        AnalyzeResourceStrategy(),
        PlanSQLTaskStrategy(),
        GenerateSQLCodeStrategy(),
    ]

    engine = WorkflowEngine(strategies)
    await engine.run(context)


# å¯åŠ¨
try:
    asyncio.run(main())
except RuntimeError:
    import nest_asyncio
    nest_asyncio.apply()
    asyncio.get_event_loop().run_until_complete(main())

```

```
[ä¿å­˜] 01_åˆ†æèµ„æº å·²å†™å…¥: output/steps\01_åˆ†æèµ„æº.md
[ä¿å­˜] 02_ä»»åŠ¡è§„åˆ’ å·²å†™å…¥: output/steps\02_ä»»åŠ¡è§„åˆ’.md
[ä¿å­˜] 03_SQLä»£ç ç”Ÿæˆ å·²å†™å…¥: output/steps\03_SQLä»£ç ç”Ÿæˆ.md
[ä¿å­˜] æœ€ç»ˆä»£ç å·²å†™å…¥: output/final_code.sql
```

````python
import os
import json
import asyncio
from abc import ABC, abstractmethod
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider


# é…ç½® Qwen API
QWEN_API = "sk-xxx"

def create_agent(prompt: str):
    provider = OpenAIProvider(
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        api_key=QWEN_API,
    )
    model = OpenAIModel(model_name="qwen-plus-latest", provider=provider)
    agent = Agent(model=model)

    @agent.system_prompt
    def dynamic_prompt(_):
        return prompt

    return agent


class FileManager:
    @staticmethod
    def load_data_files(data_dir="data"):
        files = {}
        for f in os.listdir(data_dir):
            path = os.path.join(data_dir, f)
            if os.path.isfile(path):
                with open(path, "r", encoding="utf-8") as file:
                    files[f] = file.read()
        return files

    @staticmethod
    def save_markdown_step(name, content, out_dir="output/steps"):
        os.makedirs(out_dir, exist_ok=True)
        file_path = os.path.join(out_dir, f"{name}.md")
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"# {name}\n\n{content}")
        print(f"[ä¿å­˜] {name} å·²å†™å…¥: {file_path}")

    @staticmethod
    def save_final_code(content, out_file="output/final_code.sql"):
        os.makedirs(os.path.dirname(out_file), exist_ok=True)
        with open(out_file, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"[ä¿å­˜] æœ€ç»ˆä»£ç å·²å†™å…¥: {out_file}")


class Context:
    def __init__(self, data_files):
        self.data_files = data_files
        self._results = {}

    def add_result(self, key, value):
        self._results[key] = value

    def get_result(self, key):
        return self._results.get(key, "")


class TaskStrategy(ABC):
    @abstractmethod
    async def run(self, context: Context):
        ...


class AnalyzeResourceStrategy(TaskStrategy):
    async def run(self, context: Context):
        files = list(context.data_files.keys())
        prompt = f"""
ä½ æ˜¯ä¸€ä½é«˜çº§ SQL ä½œä¸šåŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æä¾›çš„æ–‡ä»¶èµ„æºï¼Œç¡®å®šå“ªäº›æ–‡ä»¶å¯¹å®Œæˆ SQL ä½œä¸šæœ€æœ‰å¸®åŠ©ï¼Œå¹¶è§£é‡Šé€‰æ‹©ç†ç”±ã€‚
è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¦æ±‚è¾“å‡ºç»“æ„åŒ–ç»“æœï¼š
1. ä»¥ JSON æ ¼å¼è¿”å›ï¼›
2. å¿…é¡»åŒ…å« "selected_files" ï¼ˆæ•°ç»„ï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« file_name å’Œ reasonï¼›
3. å¿…é¡»åŒ…å« "skipped_files" ï¼ˆæ•°ç»„ï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« file_name å’Œ reasonï¼›
4. ä¸å…è®¸è¾“å‡ºå¤šä½™æ–‡å­—ï¼Œç»“æœå¿…é¡»æ˜¯æœ‰æ•ˆ JSONï¼›
5. è¾“å‡ºå¿…é¡»ç¬¦åˆä»¥ä¸‹ JSON Schemaï¼š
{{
  "type": "object",
  "properties": {{
    "selected_files": {{
      "type": "array",
      "items": {{
        "type": "object",
        "properties": {{
          "file_name": {{"type": "string"}},
          "reason": {{"type": "string"}}
        }},
        "required": ["file_name", "reason"]
      }}
    }},
    "skipped_files": {{
      "type": "array",
      "items": {{
        "type": "object",
        "properties": {{
          "file_name": {{"type": "string"}},
          "reason": {{"type": "string"}}
        }},
        "required": ["file_name", "reason"]
      }}
    }}
  }},
  "required": ["selected_files", "skipped_files"]
}}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
å¯ç”¨æ–‡ä»¶åˆ—è¡¨: {files}

è¯·ä»”ç»†é˜…è¯»æ–‡ä»¶åï¼ŒåŸºäºæ–‡ä»¶ååˆ¤æ–­å†…å®¹ç”¨é€”ï¼Œä¾‹å¦‚åŒ…å«.sql æ˜¯SQLæ–‡ä»¶ï¼ŒåŒ…å«quest æ˜¯é¢˜ç›®æ–‡ä»¶ç­‰ã€‚
æœ€ç»ˆè¾“å‡ºçº¯ JSONï¼Œä¸åŒ…å«è§£é‡Šã€‚
        """.strip()
        agent = create_agent(prompt)
        result = await agent.run("")
        FileManager.save_markdown_step("01_åˆ†æèµ„æº", result.output)
        context.add_result("resource_analysis", result.output)


class PlanSQLTaskStrategy(TaskStrategy):
    async def run(self, context: Context):
        analysis = context.get_result("resource_analysis")
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸š SQL ä½œä¸šè§„åˆ’ä¸“å®¶ï¼Œæ ¹æ®åˆ†æç»“æœï¼Œåˆ¶å®šå®Œæ•´ SQL ä½œä¸šè®¡åˆ’ã€‚
è¦æ±‚ï¼š
1. è¾“å‡ºå¿…é¡»æ˜¯ JSON æ ¼å¼ï¼ŒåŒ…å« task_listï¼ˆæ¯é¢˜ä¿¡æ¯ï¼‰ï¼Œæ¯é¢˜åŒ…å« question, plan, validation_planï¼›
2. JSON å¿…é¡»ç¬¦åˆä»¥ä¸‹ JSON Schemaï¼š
{{
  "type": "object",
  "properties": {{
    "task_list": {{
      "type": "array",
      "items": {{
        "type": "object",
        "properties": {{
          "question": {{"type": "string"}},
          "plan": {{"type": "string"}},
          "validation_plan": {{"type": "string"}}
        }},
        "required": ["question", "plan", "validation_plan"]
      }}
    }}
  }},
  "required": ["task_list"]
}}
3. ä¸å¾—åŒ…å«æ— å…³æ–‡å­—ï¼Œç›´æ¥è¾“å‡º JSONã€‚
ä¸Šä¸‹æ–‡ï¼šå·²é€‰æ–‡ä»¶åˆ†æç»“æœ: {analysis}
        """.strip()
        agent = create_agent(prompt)
        result = await agent.run("")
        FileManager.save_markdown_step("02_ä»»åŠ¡è§„åˆ’", result.output)
        context.add_result("task_plan", result.output)


class GenerateSQLCodeStrategy(TaskStrategy):
    async def run(self, context: Context):
        plan = context.get_result("task_plan")
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸š SQL ä»£ç ç”Ÿæˆä¸“å®¶ï¼Œä½ çš„èŒè´£æ˜¯åŸºäºç»™å®š SQL ä½œä¸šä»»åŠ¡è®¡åˆ’ï¼Œç”Ÿæˆå®Œæ•´ SQL ä½œä¸šä»£ç ã€‚
å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¦æ±‚ï¼š
1ï¸âƒ£ è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ JSON æ ¼å¼ï¼Œä¸å…è®¸è¾“å‡ºä»£ç å—æ ‡è®°ã€æ³¨é‡Šã€è§£é‡Šæˆ–å¤šä½™å†…å®¹ï¼›
2ï¸âƒ£ JSON å¿…é¡»ç¬¦åˆä»¥ä¸‹ Schemaï¼š
{{
  "type": "object",
  "properties": {{
    "final_sql": {{"type": "string"}}
  }},
  "required": ["final_sql"]
}}
3ï¸âƒ£ final_sql ä¸­åŒ…å«å®Œæ•´ SQL ä»£ç ï¼Œæ¯é“é¢˜ç”¨é¢˜å·å’Œæ€è·¯æ³¨é‡Šå¼€å¤´ï¼Œåè·Ÿ SQLã€‚
4ï¸âƒ£ ç¦æ­¢è¾“å‡ºä»»ä½•å¤šä½™ä¿¡æ¯ï¼Œä»…è¾“å‡ºç¬¦åˆ JSON Schema çš„ JSONã€‚

ä¸Šä¸‹æ–‡ä»»åŠ¡è®¡åˆ’ï¼š
{plan}

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸Šè¦æ±‚ï¼
        """.strip()

        agent = create_agent(prompt)
        result = await agent.run("")

        # ä¿å­˜ä¸­é—´æ–‡ä»¶
        FileManager.save_markdown_step("03_SQLä»£ç ç”Ÿæˆ", result.output)

        # è¾“å‡ºè°ƒè¯•æŸ¥çœ‹
        print("æ¨¡å‹è¾“å‡ºï¼š", result.output)

        # ç®€å•æ¸…æ´—
        cleaned = result.output.strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned.replace("```json", "").strip()
        if cleaned.endswith("```"):
            cleaned = cleaned[:-3].strip()

        try:
            sql_data = json.loads(cleaned)
            FileManager.save_final_code(sql_data["final_sql"])
            context.add_result("sql_code", cleaned)
        except json.JSONDecodeError:
            print("âŒ æ— æ³•è§£æ JSONï¼Œæ¨¡å‹è¾“å‡ºäº†éæ³•ç»“æœã€‚è¯·æ£€æŸ¥ä¸Šæ–¹æ‰“å°çš„æ¨¡å‹è¾“å‡ºã€‚")
            raise


class WorkflowEngine:
    def __init__(self, strategies):
        self.strategies = strategies

    async def run(self, context: Context):
        for strategy in self.strategies:
            await strategy.run(context)


async def main():
    data_files = FileManager.load_data_files()
    context = Context(data_files)

    strategies = [
        AnalyzeResourceStrategy(),
        PlanSQLTaskStrategy(),
        GenerateSQLCodeStrategy(),
    ]

    engine = WorkflowEngine(strategies)
    await engine.run(context)


try:
    asyncio.run(main())
except RuntimeError:
    import nest_asyncio
    nest_asyncio.apply()
    asyncio.get_event_loop().run_until_complete(main())

````

````
[ä¿å­˜] 01_åˆ†æèµ„æº å·²å†™å…¥: output/steps\01_åˆ†æèµ„æº.md
[ä¿å­˜] 02_ä»»åŠ¡è§„åˆ’ å·²å†™å…¥: output/steps\02_ä»»åŠ¡è§„åˆ’.md
[ä¿å­˜] 03_SQLä»£ç ç”Ÿæˆ å·²å†™å…¥: output/steps\03_SQLä»£ç ç”Ÿæˆ.md
æ¨¡å‹è¾“å‡ºï¼š ```json
{
  "final_sql": "-- 1. å¦‚ä½•æŸ¥è¯¢æ‰€æœ‰å­¦ç”Ÿçš„å§“ååŠå…¶æ‰€åœ¨ç­çº§åç§°ï¼Ÿ\nSELECT s.name AS student_name, c.name AS class_name\nFROM student s\nJOIN class c ON s.class_id = c.id;\n\n-- 2. å¦‚ä½•åˆ—å‡ºæ¯ä¸ªå­¦ç”Ÿçš„é€‰è¯¾æ•°é‡ï¼Ÿ\nSELECT s.name AS student_name, COUNT(sc.course_id) AS course_count\nFROM student s\nLEFT JOIN student_course sc ON s.id = sc.student_id\nGROUP BY s.id;\n\n-- 3. å¦‚ä½•æŸ¥è¯¢æ¯é—¨è¯¾ç¨‹çš„é€‰ä¿®äººæ•°ï¼Ÿ\nSELECT co.name AS course_name, COUNT(sc.student_id) AS student_count\nFROM course co\nLEFT JOIN student_course sc ON co.id = sc.course_id\nGROUP BY co.id;\n\n-- 4. å¦‚ä½•æ‰¾åˆ°æ²¡æœ‰é€‰ä¿®ä»»ä½•è¯¾ç¨‹çš„å­¦ç”Ÿï¼Ÿ\nSELECT s.name AS student_name\nFROM student s\nLEFT JOIN student_course sc ON s.id = sc.student_id\nWHERE sc.course_id IS NULL;\n\n-- 5. å¦‚ä½•æŸ¥è¯¢é€‰ä¿®äº†å…¨éƒ¨è¯¾ç¨‹çš„å­¦ç”Ÿï¼Ÿ\nSELECT s.name AS student_name\nFROM student s\nJOIN student_course sc ON s.id = sc.student_id\nGROUP BY s.id\nHAVING COUNT(DISTINCT sc.course_id) = (SELECT COUNT(*) FROM course);"
}
````

[ä¿å­˜] æœ€ç»ˆä»£ç å·²å†™å…¥: output/final_code.sql

````

```python
import os
import json
import asyncio
from dataclasses import dataclass
from typing import List, Dict, Any

# å‡è®¾ç”¨çš„æ˜¯ pydantic_ai æˆ–ç±»ä¼¼æ¡†æ¶
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider

# é…ç½®æ¨¡å‹ï¼ˆè¯·æ›¿æ¢æˆä½ çš„ keyï¼‰
provider = OpenAIProvider(
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key="sk-xxx",
)
model = OpenAIModel(model_name="qwen-plus-latest", provider=provider)

# æ–‡ä»¶åŠ©æ‰‹
class FileManager:
    @staticmethod
    def read_file(path: str) -> str:
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()

    @staticmethod
    def save_markdown_step(step_name: str, content: str):
        with open(f"outputs/{step_name}.md", 'w', encoding='utf-8') as f:
            f.write(content)

    @staticmethod
    def save_sql_file(sql_code: str):
        with open("outputs/final_sql.sql", 'w', encoding='utf-8') as f:
            f.write(sql_code)

os.makedirs("outputs", exist_ok=True)

# ä¸Šä¸‹æ–‡
@dataclass
class Context:
    data: Dict[str, Any]

    def add(self, key: str, value: Any):
        self.data[key] = value

    def get(self, key: str) -> Any:
        return self.data.get(key)

# ç­–ç•¥åŸºç±»
class TaskStrategy:
    async def run(self, ctx: Context):
        raise NotImplementedError

# è¯»å–æ•°æ®æ–‡ä»¶ç­–ç•¥
class LoadResourcesStrategy(TaskStrategy):
    async def run(self, ctx: Context):
        quest = FileManager.read_file("data/å­¦ç”Ÿå¤šè¡¨ç»ƒä¹ .sql")
        demo_sql = FileManager.read_file("data/æ•°æ®æºæ–‡ä»¶.sql")
        ctx.add("quest", quest)
        ctx.add("demo_sql", demo_sql)
        FileManager.save_markdown_step("01_èµ„æºè¯»å–", f"### ä½œä¸šé¢˜ç›®\n```\n{quest}\n```\n\n### æ•°æ®ç»“æ„\n```\n{demo_sql}\n```")

# ç”Ÿæˆé¢˜è§£ç­–ç•¥
class PlanSolutionStrategy(TaskStrategy):
    async def run(self, ctx: Context):
        quest = ctx.get("quest")
        demo_sql = ctx.get("demo_sql")
        prompt = f"""
ä½ æ˜¯ä¸€ä½é«˜çº§SQLä½œä¸šåˆ†æä¸“å®¶ï¼Œä½ æ”¶åˆ°äº†ä¸€ä»½å¤šè¡¨æŸ¥è¯¢ç»ƒä¹ ä½œä¸šé¢˜ç›®å’Œç¤ºä¾‹æ•°æ®åº“ç»“æ„ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œè¾“å‡ºå®Œæ•´çš„é¢˜è§£æ€è·¯è§„åˆ’ã€‚

âš ï¸ è¾“å‡ºè¦æ±‚ï¼š
- å¿…é¡»æ˜¯ä¸¥æ ¼ JSON æ ¼å¼ï¼Œç¦æ­¢åŒ…å«ä»£ç å—æ ‡è®°ã€è§£é‡Šã€æ³¨é‡Šç­‰ã€‚
- JSON ç»“æ„å¦‚ä¸‹ï¼š
{{
  "solutions": [
    {{
      "question": "é¢˜ç›®å†…å®¹",
      "thinking": "è¯¦ç»†çš„è§£é¢˜æ€è·¯ï¼ˆä¸å°‘äº100å­—ï¼‰"
    }}
  ]
}}
- solutions ä¸­åŒ…å«æ‰€æœ‰é¢˜ç›®ã€‚
- ç¦æ­¢è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚

ä½œä¸šé¢˜ç›®ï¼š
{quest}

ç¤ºä¾‹æ•°æ®ç»“æ„ï¼š
{demo_sql}
        """.strip()

        agent = Agent(model=model)
        result = await agent.run(prompt)
        cleaned = result.output.strip().strip('```').strip('json').strip()
        FileManager.save_markdown_step("02_é¢˜è§£è§„åˆ’", cleaned)
        ctx.add("solution_plan", json.loads(cleaned))

# ç”Ÿæˆ SQL ä»£ç ç­–ç•¥
class GenerateSQLCodeStrategy(TaskStrategy):
    async def run(self, ctx: Context):
        solution_plan = ctx.get("solution_plan")
        demo_sql = ctx.get("demo_sql")
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šSQLä½œä¸šä»£ç ç”Ÿæˆä¸“å®¶ï¼ŒåŸºäºä»¥ä¸‹è§£é¢˜æ€è·¯å’Œæ•°æ®åº“ç»“æ„ï¼Œç”Ÿæˆå®Œæ•´ä½œä¸šä»£ç ã€‚

âš ï¸ è¾“å‡ºè¦æ±‚ï¼š
- å¿…é¡»æ˜¯ä¸¥æ ¼ JSON æ ¼å¼ã€‚
- JSON ç»“æ„ï¼š
{{
  "final_sql": "å®Œæ•´ SQL ä½œä¸šä»£ç ï¼Œæ¯é“é¢˜å«æ€è·¯æ³¨é‡Š + SQL è¯­å¥"
}}
- ç¦æ­¢åŒ…å«ä»£ç å—æ ‡è®°ã€é¢å¤–è¯´æ˜æˆ–ä»»ä½•é JSON å†…å®¹ã€‚

è§£é¢˜æ€è·¯ï¼š
{json.dumps(solution_plan, ensure_ascii=False)}

æ•°æ®åº“ç»“æ„ï¼š
{demo_sql}
        """.strip()

        agent = Agent(model=model)
        result = await agent.run(prompt)
        cleaned = result.output.strip().strip('```').strip('json').strip()
        FileManager.save_markdown_step("03_SQLä»£ç ç”Ÿæˆ", cleaned)
        sql_data = json.loads(cleaned)
        FileManager.save_sql_file(sql_data["final_sql"])
        ctx.add("final_sql", sql_data["final_sql"])

# å·¥ä½œæµå¼•æ“
class WorkflowEngine:
    def __init__(self, strategies: List[TaskStrategy]):
        self.strategies = strategies

    async def run(self, ctx: Context):
        for s in self.strategies:
            await s.run(ctx)

# ä¸»å‡½æ•°
async def main():
    ctx = Context(data={})
    strategies = [
        LoadResourcesStrategy(),
        PlanSolutionStrategy(),
        GenerateSQLCodeStrategy()
    ]
    engine = WorkflowEngine(strategies)
    await engine.run(ctx)
    print("âœ… å·¥ä½œæµå·²å®Œæˆï¼Œæœ€ç»ˆ SQL æ–‡ä»¶å·²ä¿å­˜åˆ° outputs/final_sql.sql")

try:
    asyncio.run(main())
except RuntimeError:
    import nest_asyncio
    nest_asyncio.apply()
    asyncio.run(main())

````

```
âœ… å·¥ä½œæµå·²å®Œæˆï¼Œæœ€ç»ˆ SQL æ–‡ä»¶å·²ä¿å­˜åˆ° outputs/final_sql.sql
```
